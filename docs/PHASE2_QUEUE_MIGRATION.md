# Project Aether - Phase 2: Queue Migration

**Status**: üü° IN PROGRESS
**Date**: 2025-11-28
**Phase**: Queue Migration (Week 3-4)

## Overview

Phase 2 replaces the in-memory `JobQueue` with PgQueuer - a high-performance PostgreSQL-based queue system that provides durable, distributed job queuing with 18k+ jobs/sec throughput.

## Completed Tasks ‚úÖ

### 1. Infrastructure Package Created

Created `src/casare_rpa/infrastructure/queue/` package with complete PgQueuer implementation:

**Files Created**:
- [`__init__.py`](src/casare_rpa/infrastructure/queue/__init__.py) - Package exports
- [`models.py`](src/casare_rpa/infrastructure/queue/models.py) - Job data models
- [`config.py`](src/casare_rpa/infrastructure/queue/config.py) - Configuration management
- [`producer.py`](src/casare_rpa/infrastructure/queue/producer.py) - Job queue producer
- [`consumer.py`](src/casare_rpa/infrastructure/queue/consumer.py) - Job queue consumer

### 2. Job Data Models

**JobModel** - Complete job lifecycle management:
- Status tracking (pending ‚Üí claimed ‚Üí running ‚Üí completed/failed)
- Priority levels (0-20, higher = more urgent)
- Retry logic with configurable max attempts
- Visibility timeout pattern
- Multi-tenancy support (tenant_id)
- Metadata & tags for filtering

**JobStatus Enum**:
- `PENDING` - Waiting in queue
- `CLAIMED` - Claimed by robot (visibility timeout active)
- `RUNNING` - Currently executing
- `COMPLETED` - Successfully completed
- `FAILED` - Failed (moved to DLQ after max retries)
- `CANCELLED` - Cancelled by user/system

**JobPriority Enum**: LOW (0), NORMAL (5), HIGH (10), URGENT (15), CRITICAL (20)

### 3. Queue Configuration

**QueueConfig** class with support for:
- Environment variable loading
- Supabase connection configuration
- Local PostgreSQL development
- Configurable concurrency, timeouts, retries
- Connection pooling settings

**Configuration Options**:
```python
- database_url: PostgreSQL connection string
- queue_name: Queue identifier (allows multiple queues)
- max_concurrent_jobs: Concurrent jobs per robot (default: 3)
- visibility_timeout: Claim timeout in seconds (default: 30)
- poll_interval: Polling frequency (default: 1.0s)
- max_retries: Max attempts before DLQ (default: 3)
- enable_dlq: Dead Letter Queue enabled (default: true)
- batch_size: Jobs per poll (default: 10)
- connection_pool_size: DB pool size (default: 10)
```

### 4. PgQueuerProducer (Orchestrator)

**Features**:
- ‚úÖ Priority-based job enqueueing
- ‚úÖ Async job submission
- ‚úÖ Connection pooling
- ‚úÖ Batch job submission
- ‚úÖ Queue depth monitoring
- ‚úÖ Job status tracking
- ‚úÖ Job cancellation
- ‚úÖ Health checks
- ‚úÖ Queue purging (admin)

**Key Methods**:
- `enqueue_job()` - Enqueue single job with priority
- `enqueue_batch()` - Batch job submission
- `get_queue_depth()` - Get pending job count
- `get_job_status()` - Check job status
- `cancel_job()` - Cancel pending/claimed job
- `health_check()` - Database connectivity check

### 5. PgQueuerConsumer (Robot)

**Features**:
- ‚úÖ Priority-based job claiming
- ‚úÖ Visibility timeout pattern (prevents duplicate processing)
- ‚úÖ Heartbeat mechanism (extends timeout for long-running jobs)
- ‚úÖ Dead Letter Queue integration
- ‚úÖ Concurrent job execution
- ‚úÖ Automatic retry logic
- ‚úÖ Graceful shutdown with job release

**Key Methods**:
- `claim_job()` - Claim next job from queue (SKIP LOCKED)
- `complete_job()` - Mark job as completed
- `fail_job()` - Mark job as failed (retry or DLQ)
- `release_job()` - Release claimed job back to queue
- Heartbeat loop - Extends visibility timeout for active jobs

### 6. Integration Tests

Created [`tests/infrastructure/test_pgqueuer_integration.py`](tests/infrastructure/test_pgqueuer_integration.py):

**Test Coverage**:
- ‚úÖ Configuration loading (env, Supabase, local)
- ‚úÖ Job model lifecycle
- ‚úÖ Job retry logic
- ‚úÖ Producer lifecycle
- ‚úÖ Consumer lifecycle
- ‚è∏Ô∏è Full producer-consumer flow (requires Postgres)

## Architecture

### Queue Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Orchestrator   ‚îÇ
‚îÇ                  ‚îÇ
‚îÇ  Producer.       ‚îÇ
‚îÇ  enqueue_job()   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      PostgreSQL + PgQueuer      ‚îÇ
‚îÇ                                 ‚îÇ
‚îÇ  Queue: casare_rpa_jobs         ‚îÇ
‚îÇ  - Priority ordering            ‚îÇ
‚îÇ  - LISTEN/NOTIFY                ‚îÇ
‚îÇ  - Visibility timeout           ‚îÇ
‚îÇ  - Dead Letter Queue            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Robot Agent    ‚îÇ
‚îÇ                  ‚îÇ
‚îÇ  Consumer.       ‚îÇ
‚îÇ  claim_job()     ‚îÇ
‚îÇ  ‚Üí execute       ‚îÇ
‚îÇ  ‚Üí complete/fail ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Visibility Timeout Pattern

```
Job State Timeline:

PENDING ‚Üí CLAIMED (30s timeout) ‚Üí RUNNING ‚Üí COMPLETED
    ‚Üì                                ‚Üì
    ‚îî‚îÄ‚îÄ(timeout expires)‚îÄ‚îÄ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         back to PENDING

Heartbeat extends timeout every 15s
```

### Dead Letter Queue

```
Job Retry Flow:

PENDING ‚Üí CLAIMED ‚Üí FAILED (retry 1/3)
     ‚Üì         ‚Üì
     ‚îî‚îÄ(retry)‚îÄ‚îò

PENDING ‚Üí CLAIMED ‚Üí FAILED (retry 2/3)
     ‚Üì         ‚Üì
     ‚îî‚îÄ(retry)‚îÄ‚îò

PENDING ‚Üí CLAIMED ‚Üí FAILED (retry 3/3)
                      ‚Üì
                    DLQ (manual intervention)
```

## Pending Tasks üîÑ

### 1. Migrate Orchestrator (Next)

**Files to Modify**:
- [src/casare_rpa/orchestrator/engine.py](src/casare_rpa/orchestrator/engine.py)
  - Replace `JobQueue` with `PgQueuerProducer`
  - Update dispatcher to use `enqueue_job()`
  - Add queue depth monitoring

- [src/casare_rpa/orchestrator/job_queue.py](src/casare_rpa/orchestrator/job_queue.py)
  - DELETE (in-memory queue no longer needed)

### 2. Migrate Robot Agent (Next)

**Files to Modify**:
- [src/casare_rpa/robot/agent.py](src/casare_rpa/robot/agent.py)
  - Replace polling logic with `PgQueuerConsumer`
  - Integrate `claim_job()` / `complete_job()` / `fail_job()`
  - Add heartbeat integration

- [src/casare_rpa/robot/job_executor.py](src/casare_rpa/robot/job_executor.py)
  - Track claimed jobs
  - Integrate with queue consumer lifecycle

### 3. Database Setup

**PostgreSQL Schema**:
```sql
-- Install PgQueuer extension
CREATE EXTENSION IF NOT EXISTS pgqueuer;

-- PgQueuer automatically creates these tables:
-- - pgqueuer.jobs (main queue)
-- - pgqueuer.dead_letter_queue
-- - pgqueuer.job_history

-- Add indexes for performance
CREATE INDEX IF NOT EXISTS idx_jobs_status_priority
ON pgqueuer.jobs(status, priority DESC, created_at);

CREATE INDEX IF NOT EXISTS idx_jobs_tenant
ON pgqueuer.jobs((payload->>'tenant_id'));
```

### 4. Configuration

**Environment Variables** (.env):
```bash
# Queue Configuration
PGQUEUER_DATABASE_URL=postgresql://postgres:password@localhost:5432/casare_rpa
PGQUEUER_QUEUE_NAME=casare_rpa_jobs
PGQUEUER_MAX_CONCURRENT=3
PGQUEUER_VISIBILITY_TIMEOUT=30
PGQUEUER_MAX_RETRIES=3
```

## Migration Strategy

### Backward Compatibility

- Keep old `JobQueue` available during transition
- Feature flag: `USE_PGQUEUER` (default: false initially)
- Gradual rollout per environment

### Data Migration

- No migration needed (in-memory queue has no persistent data)
- New jobs automatically use PgQueuer
- Existing in-flight jobs complete normally

### Testing Plan

1. Unit tests for producer/consumer (‚úÖ Complete)
2. Integration tests with local Postgres (‚è∏Ô∏è Pending CI)
3. Load testing (10k jobs/sec)
4. Failure scenario testing (crashes, network issues)
5. Multi-robot coordination testing

## Performance Targets

- **Throughput**: 10k+ jobs/day per Postgres instance
- **Latency**: Job submission ‚Üí claim < 100ms (p95)
- **Concurrency**: 100+ robots, 300+ concurrent jobs
- **Reliability**: Zero lost jobs, automatic retry
- **Visibility Timeout**: 30s default, extended via heartbeat

## Success Metrics

- ‚úÖ PgQueuer infrastructure package created
- ‚úÖ Producer implementation complete
- ‚úÖ Consumer implementation complete
- ‚úÖ Configuration system complete
- ‚úÖ Unit tests passing
- ‚è∏Ô∏è Integration tests (requires Postgres setup)
- ‚è∏Ô∏è Orchestrator migration
- ‚è∏Ô∏è Robot migration
- ‚è∏Ô∏è Load testing

## Next Steps

1. **Commit Phase 2 infrastructure** ‚úÖ
2. **Setup test PostgreSQL** (Docker Compose)
3. **Migrate orchestrator/engine.py** to use PgQueuerProducer
4. **Migrate robot/agent.py** to use PgQueuerConsumer
5. **Integration testing** with producer + consumer
6. **Performance benchmarking**

## Resources

- **Plan**: [C:\Users\Rau\.claude\plans\tender-puzzling-ullman.md](file:///C:/Users/Rau/.claude/plans/tender-puzzling-ullman.md)
- **PgQueuer Docs**: https://github.com/janbjorge/pgqueuer
- **Postgres LISTEN/NOTIFY**: https://www.postgresql.org/docs/current/sql-notify.html
- **Previous Phase**: [PHASE1_FOUNDATION.md](PHASE1_FOUNDATION.md)

---

**Status**: Infrastructure complete, orchestrator migration next
**Blockers**: None
**ETA**: Phase 2 complete by end of Week 4
