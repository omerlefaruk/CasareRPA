"""
Pydantic v2 models for AI-generated workflow validation.

These models provide strict validation for workflows generated by AI systems,
ensuring compatibility with workflow_loader.py and preventing malicious payloads.

Security Features:
- Dangerous pattern detection (eval, exec, __import__, etc.)
- Size limits (MAX_NODES, MAX_CONNECTIONS, MAX_STRING_LENGTH)
- Deep nesting prevention (MAX_CONFIG_DEPTH)
- Type validation for all fields
"""

import re
from typing import Any, ClassVar, Dict, List, Optional, Tuple

from pydantic import (
    BaseModel,
    ConfigDict,
    Field,
    field_validator,
    model_validator,
)


# Security constants aligned with workflow_loader.py
MAX_NODES: int = 1000
MAX_CONNECTIONS: int = 5000
MAX_NODE_ID_LENGTH: int = 256
MAX_CONFIG_DEPTH: int = 10
MAX_STRING_LENGTH: int = 10000

# Dangerous patterns that indicate potential code injection
DANGEROUS_PATTERNS: List[str] = [
    "__import__",
    "eval(",
    "exec(",
    "compile(",
    "os.system",
    "subprocess.",
    "open(",
    "pickle.",
    "marshal.",
    "__builtins__",
    "__globals__",
]


class SecurityValidationError(ValueError):
    """Raised when security validation fails."""

    pass


def _check_dangerous_patterns(value: str, field_path: str) -> None:
    """
    Check string for dangerous code injection patterns.

    Args:
        value: String to check
        field_path: Path to field for error reporting

    Raises:
        SecurityValidationError: If dangerous pattern found
    """
    value_lower = value.lower()
    for pattern in DANGEROUS_PATTERNS:
        if pattern in value_lower:
            raise SecurityValidationError(
                f"Security error: Dangerous pattern '{pattern}' found in {field_path}"
            )


def _validate_config_recursive(value: Any, path: str = "config", depth: int = 0) -> Any:
    """
    Recursively validate config values for security and depth.

    Args:
        value: Value to validate
        path: Current path for error reporting
        depth: Current nesting depth

    Returns:
        Validated value

    Raises:
        ValueError: If validation fails
    """
    if depth > MAX_CONFIG_DEPTH:
        raise ValueError(
            f"Config at '{path}' exceeds maximum depth of {MAX_CONFIG_DEPTH}"
        )

    if value is None:
        return value

    if isinstance(value, (bool, int, float)):
        return value

    if isinstance(value, str):
        if len(value) > MAX_STRING_LENGTH:
            raise ValueError(
                f"String at '{path}' exceeds max length {MAX_STRING_LENGTH}"
            )
        _check_dangerous_patterns(value, path)
        return value

    if isinstance(value, list):
        return [
            _validate_config_recursive(item, f"{path}[{i}]", depth + 1)
            for i, item in enumerate(value)
        ]

    if isinstance(value, dict):
        validated = {}
        for k, v in value.items():
            if not isinstance(k, str):
                raise ValueError(
                    f"Config key at '{path}' must be string, got {type(k).__name__}"
                )
            if len(k) > MAX_NODE_ID_LENGTH:
                raise ValueError(
                    f"Config key at '{path}' exceeds max length {MAX_NODE_ID_LENGTH}"
                )
            validated[k] = _validate_config_recursive(v, f"{path}.{k}", depth + 1)
        return validated

    raise ValueError(f"Unsupported type at '{path}': {type(value).__name__}")


class WorkflowMetadataSchema(BaseModel):
    """
    Schema for workflow metadata.

    Validates name (1-256 chars), description, version, author, and tags.
    """

    model_config = ConfigDict(extra="forbid", str_strip_whitespace=True)

    name: str = Field(
        ...,
        min_length=1,
        max_length=256,
        description="Workflow name (required, 1-256 characters)",
    )
    description: str = Field(
        default="",
        max_length=MAX_STRING_LENGTH,
        description="Workflow description",
    )
    version: str = Field(
        default="1.0.0",
        max_length=50,
        pattern=r"^\d+\.\d+\.\d+$",
        description="Semantic version (e.g., 1.0.0)",
    )
    author: str = Field(
        default="",
        max_length=256,
        description="Workflow author",
    )
    tags: List[str] = Field(
        default_factory=list,
        max_length=50,
        description="List of tags for categorization",
    )

    @field_validator("name")
    @classmethod
    def validate_name_not_whitespace(cls, v: str) -> str:
        """Ensure name is not whitespace-only."""
        if not v.strip():
            raise ValueError("Workflow name cannot be whitespace-only")
        _check_dangerous_patterns(v, "metadata.name")
        return v

    @field_validator("description")
    @classmethod
    def validate_description_security(cls, v: str) -> str:
        """Check description for dangerous patterns."""
        if v:
            _check_dangerous_patterns(v, "metadata.description")
        return v

    @field_validator("tags")
    @classmethod
    def validate_tags(cls, v: List[str]) -> List[str]:
        """Validate each tag."""
        for i, tag in enumerate(v):
            if len(tag) > 100:
                raise ValueError(f"Tag {i} exceeds max length of 100")
            _check_dangerous_patterns(tag, f"metadata.tags[{i}]")
        return v

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dict compatible with workflow_loader."""
        return {
            "name": self.name,
            "description": self.description,
            "version": self.version,
            "author": self.author,
            "tags": self.tags,
        }


class NodeConfigSchema(BaseModel):
    """
    Schema for node configuration.

    Flexible dict with security validation for dangerous patterns
    and nesting depth limits.
    """

    model_config = ConfigDict(extra="allow")

    @model_validator(mode="before")
    @classmethod
    def validate_config_security(cls, values: Any) -> Any:
        """Validate entire config dict for security."""
        if isinstance(values, dict):
            return _validate_config_recursive(values, "config", 0)
        return values

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dict."""
        return dict(self)


class PositionSchema(BaseModel):
    """Optional position for node placement in canvas."""

    model_config = ConfigDict(extra="forbid")

    x: float = Field(default=0.0, description="X coordinate")
    y: float = Field(default=0.0, description="Y coordinate")


class NodeSchema(BaseModel):
    """
    Schema for a workflow node.

    Validates node_id (max 256 chars), node_type (max 128 chars),
    config dict, and optional position.
    """

    model_config = ConfigDict(extra="forbid")

    node_id: str = Field(
        ...,
        min_length=1,
        max_length=MAX_NODE_ID_LENGTH,
        description="Unique node identifier",
    )
    node_type: str = Field(
        ...,
        min_length=1,
        max_length=128,
        description="Node type name (e.g., ClickElementNode)",
    )
    config: Dict[str, Any] = Field(
        default_factory=dict,
        description="Node configuration parameters",
    )
    position: Optional[PositionSchema] = Field(
        default=None,
        description="Optional canvas position",
    )

    @field_validator("node_id")
    @classmethod
    def validate_node_id(cls, v: str) -> str:
        """Validate node_id format and security."""
        if not v.strip():
            raise ValueError("node_id cannot be whitespace-only")
        # Allow alphanumeric, underscore, hyphen
        if not re.match(r"^[a-zA-Z0-9_-]+$", v):
            raise ValueError("node_id must be alphanumeric with _ or - only")
        _check_dangerous_patterns(v, "node_id")
        return v

    @field_validator("node_type")
    @classmethod
    def validate_node_type(cls, v: str) -> str:
        """Validate node_type format."""
        if not v.strip():
            raise ValueError("node_type cannot be whitespace-only")
        # Must be valid Python class name format
        if not re.match(r"^[A-Z][a-zA-Z0-9]*Node$", v):
            raise ValueError("node_type must be PascalCase ending with 'Node'")
        return v

    @field_validator("config")
    @classmethod
    def validate_config(cls, v: Dict[str, Any]) -> Dict[str, Any]:
        """Validate config dict for security."""
        return _validate_config_recursive(v, "config", 0)

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dict compatible with workflow_loader."""
        result = {
            "node_id": self.node_id,
            "node_type": self.node_type,
            "config": self.config,
        }
        if self.position:
            # Output as [x, y] list for workflow_loader compatibility
            result["position"] = [self.position.x, self.position.y]
        return result


class ConnectionSchema(BaseModel):
    """
    Schema for a connection between nodes.

    Validates source/target node IDs and port names.
    """

    model_config = ConfigDict(extra="forbid")

    source_node: str = Field(
        ...,
        min_length=1,
        max_length=MAX_NODE_ID_LENGTH,
        description="Source node ID",
    )
    source_port: str = Field(
        ...,
        min_length=1,
        max_length=128,
        description="Source port name (e.g., exec_out, result)",
    )
    target_node: str = Field(
        ...,
        min_length=1,
        max_length=MAX_NODE_ID_LENGTH,
        description="Target node ID",
    )
    target_port: str = Field(
        ...,
        min_length=1,
        max_length=128,
        description="Target port name (e.g., exec_in, value)",
    )

    @field_validator("source_node", "target_node")
    @classmethod
    def validate_node_ids(cls, v: str) -> str:
        """Validate node ID format."""
        if not v.strip():
            raise ValueError("node ID cannot be whitespace-only")
        if not re.match(r"^[a-zA-Z0-9_-]+$", v):
            raise ValueError("node ID must be alphanumeric with _ or - only")
        return v

    @field_validator("source_port", "target_port")
    @classmethod
    def validate_port_names(cls, v: str) -> str:
        """Validate port name format."""
        if not v.strip():
            raise ValueError("port name cannot be whitespace-only")
        # Port names are snake_case
        if not re.match(r"^[a-z][a-z0-9_]*$", v):
            raise ValueError("port name must be snake_case")
        return v

    def to_dict(self) -> Dict[str, str]:
        """Serialize to dict compatible with workflow_loader."""
        return {
            "source_node": self.source_node,
            "source_port": self.source_port,
            "target_node": self.target_node,
            "target_port": self.target_port,
        }


class WorkflowSettingsSchema(BaseModel):
    """
    Schema for workflow execution settings.

    Controls error handling, timeouts, and retry behavior.
    """

    model_config = ConfigDict(extra="forbid")

    stop_on_error: bool = Field(
        default=True,
        description="Stop execution on first error",
    )
    timeout: int = Field(
        default=30,
        ge=1,
        le=3600,
        description="Global timeout in seconds (1-3600)",
    )
    retry_count: int = Field(
        default=0,
        ge=0,
        le=10,
        description="Number of retries on failure (0-10)",
    )

    def to_dict(self) -> Dict[str, Any]:
        """Serialize to dict."""
        return {
            "stop_on_error": self.stop_on_error,
            "timeout": self.timeout,
            "retry_count": self.retry_count,
        }


class WorkflowAISchema(BaseModel):
    """
    Complete workflow schema for AI generation.

    Validates entire workflow structure including metadata, nodes,
    connections, variables, and settings. Enforces size limits
    and security constraints.
    """

    model_config = ConfigDict(extra="forbid")

    # JSON schema hints for AI systems
    _JSON_SCHEMA_HINTS: ClassVar[Dict[str, str]] = {
        "node_types": "Use PascalCase ending with 'Node' (e.g., ClickElementNode, NavigateNode)",
        "node_id_format": "Use descriptive IDs with underscores (e.g., click_login_button)",
        "port_names": "exec_in/exec_out for flow, snake_case for data (e.g., selector, timeout)",
        "connections": "Connect exec_out to exec_in for flow, data ports for values",
        "common_nodes": "StartNode, ClickElementNode, TypeTextNode, NavigateNode, WaitNode",
    }

    metadata: WorkflowMetadataSchema = Field(
        ...,
        description="Workflow metadata (name, description, version, etc.)",
    )
    nodes: Dict[str, NodeSchema] = Field(
        default_factory=dict,
        description="Map of node_id to NodeSchema",
    )
    connections: List[ConnectionSchema] = Field(
        default_factory=list,
        description="List of connections between nodes",
    )
    variables: Dict[str, Any] = Field(
        default_factory=dict,
        description="Workflow-level variables",
    )
    settings: WorkflowSettingsSchema = Field(
        default_factory=WorkflowSettingsSchema,
        description="Execution settings",
    )

    @model_validator(mode="after")
    def validate_workflow_limits(self) -> "WorkflowAISchema":
        """Validate workflow-level constraints."""
        # Check node count
        if len(self.nodes) > MAX_NODES:
            raise ValueError(f"Workflow exceeds maximum of {MAX_NODES} nodes")

        # Check connection count
        if len(self.connections) > MAX_CONNECTIONS:
            raise ValueError(
                f"Workflow exceeds maximum of {MAX_CONNECTIONS} connections"
            )

        # Validate node_id consistency (dict key must match node.node_id)
        for node_id, node in self.nodes.items():
            if node_id != node.node_id:
                raise ValueError(
                    f"Node key '{node_id}' does not match node.node_id '{node.node_id}'"
                )

        # Validate connection references
        node_ids = set(self.nodes.keys())
        for i, conn in enumerate(self.connections):
            if conn.source_node not in node_ids:
                raise ValueError(
                    f"Connection {i}: source_node '{conn.source_node}' not found"
                )
            if conn.target_node not in node_ids:
                raise ValueError(
                    f"Connection {i}: target_node '{conn.target_node}' not found"
                )

        # Validate variables for security
        self._validate_variables()

        return self

    def _validate_variables(self) -> None:
        """Validate workflow variables for security."""
        _validate_config_recursive(self.variables, "variables", 0)

    def to_dict(self) -> Dict[str, Any]:
        """
        Serialize to dict compatible with workflow_loader.py.

        Returns:
            Dictionary matching workflow_loader expected structure
        """
        return {
            "metadata": self.metadata.to_dict(),
            "nodes": {node_id: node.to_dict() for node_id, node in self.nodes.items()},
            "connections": [conn.to_dict() for conn in self.connections],
            "variables": self.variables,
            "settings": self.settings.to_dict(),
        }

    @classmethod
    def from_natural_language_hint(cls) -> Dict[str, Any]:
        """
        Provide JSON schema hints for AI workflow generation.

        Returns:
            Dictionary with schema structure and hints for AI systems
        """
        return {
            "schema_version": "1.0",
            "hints": cls._JSON_SCHEMA_HINTS,
            "structure": {
                "metadata": {
                    "name": "string (1-256 chars, required)",
                    "description": "string (optional)",
                    "version": "string (semver, default 1.0.0)",
                    "author": "string (optional)",
                    "tags": "list[string] (optional)",
                },
                "nodes": {
                    "<node_id>": {
                        "node_id": "string (must match dict key)",
                        "node_type": "string (PascalCase + Node suffix)",
                        "config": "dict (node-specific parameters)",
                        "position": {"x": "float", "y": "float"},
                    }
                },
                "connections": [
                    {
                        "source_node": "string (node_id)",
                        "source_port": "string (port name)",
                        "target_node": "string (node_id)",
                        "target_port": "string (port name)",
                    }
                ],
                "variables": {"<var_name>": "any"},
                "settings": {
                    "stop_on_error": "bool (default true)",
                    "timeout": "int (1-3600, default 30)",
                    "retry_count": "int (0-10, default 0)",
                },
            },
            "example": {
                "metadata": {
                    "name": "Login Automation",
                    "description": "Automates login flow",
                },
                "nodes": {
                    "start_node": {
                        "node_id": "start_node",
                        "node_type": "StartNode",
                        "config": {},
                    },
                    "navigate_to_login": {
                        "node_id": "navigate_to_login",
                        "node_type": "NavigateNode",
                        "config": {"url": "https://example.com/login"},
                    },
                    "click_submit": {
                        "node_id": "click_submit",
                        "node_type": "ClickElementNode",
                        "config": {"selector": "#submit-btn", "timeout": 5000},
                    },
                },
                "connections": [
                    {
                        "source_node": "start_node",
                        "source_port": "exec_out",
                        "target_node": "navigate_to_login",
                        "target_port": "exec_in",
                    },
                    {
                        "source_node": "navigate_to_login",
                        "source_port": "exec_out",
                        "target_node": "click_submit",
                        "target_port": "exec_in",
                    },
                ],
                "variables": {},
                "settings": {"stop_on_error": True, "timeout": 30, "retry_count": 0},
            },
        }

    @classmethod
    def validate_ai_output(cls, workflow_dict: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Validate AI-generated workflow JSON.

        Args:
            workflow_dict: Raw dictionary from AI output

        Returns:
            Tuple of (is_valid, error_message)
        """
        try:
            cls.model_validate(workflow_dict)
            return True, ""
        except Exception as e:
            return False, str(e)


__all__ = [
    "WorkflowMetadataSchema",
    "NodeConfigSchema",
    "NodeSchema",
    "ConnectionSchema",
    "WorkflowSettingsSchema",
    "WorkflowAISchema",
    "PositionSchema",
    "SecurityValidationError",
    "MAX_NODES",
    "MAX_CONNECTIONS",
    "MAX_NODE_ID_LENGTH",
    "MAX_CONFIG_DEPTH",
    "MAX_STRING_LENGTH",
    "DANGEROUS_PATTERNS",
]
